# 📌 Proyecto 2 - Proyecto Final MLOps - Entrenamiento y Monitoreo de Modelos

Este proyecto implementa una arquitectura completa de MLOps que permite la orquestación, entrenamiento, registro y monitoreo de modelos de machine learning mediante servicios contenedorizados e integrados en una red común (`mlops_net`).

---

## 📦 Estructura del Proyecto

```
PROYECTO_FINAL/
├── app_back/
│   ├── dockerfile_api
│   ├── main.py
│   └── requirements_api.txt
├── app_front/
│   ├── app.py
│   ├── dockerfile_stream
│   └── requirements_app.txt
├── connections/
│   ├── __init__.py
│   └── connections.py
├── dags/
│   └── pipeline.py
├── grafana/
│   └── provisioning/
│       ├── dashboards/
│       │   └── fastapi_dashboard.json
│       ├── datasources/
│       └── dashboards.yml
├── logs/
├── minio/
├── mlflow/
│   ├── dockerfile_mlflow
│   ├── init.sql
│   └── requirements_mlflow.txt
├── models/
│   ├── columnas_entrenamiento.json
│   ├── modelo_linear_regression_20250524_203129.pkl
│   ├── modelo_linear_regression_20250526_215046.pkl
│   ├── modelo_linear_regression_20250526_215231.pkl
│   └── modelo_mejor.pkl
├── prometheus/
│   └── prometheus.yml
├── docker-compose-airflow.yml
├── docker-compose-mlflow.yml
├── docker-compose.yml
├── dockerfile
└── requirements.txt
├── app_front/                 # Frontend con Streamlit
├── connections/               # Conexiones a bases de datos
├── dags/                      # DAGs de Airflow (pipeline unificado)
├── grafana/                   # Dashboards y configuración
├── logs/                      # Logs de Airflow
├── minio/                     # Almacenamiento S3
├── mlflow/                    # Configuración de MLflow
├── models/                    # Modelos y artefactos generados
├── prometheus/                # Configuración de Prometheus
├── docker-compose.yml         # Base: MySQL, MinIO, API, Streamlit
├── docker-compose-mlflow.yml  # Servicio MLflow
├── docker-compose-airflow.yml# Servicios Airflow
```

---

## 🚀 Servicios principales

| Servicio     | Puerto | Descripción |
|--------------|--------|-------------|
| **Airflow**  | `8080` | Orquestación del pipeline de datos |
| **MLflow**   | `8084` | Registro de experimentos y modelos |
| **MinIO**    | `9000`, `8083` | Almacenamiento tipo S3 para artefactos |
| **Streamlit**| `8501` | Visualización de resultados |
| **FastAPI**  | `8000` | Backend API |
| **Grafana**  | `3000` | Visualización de métricas |
| **Prometheus** | `9090` | Recolección de métricas |
| **MySQL**    | `3306` | Base de datos principal |

---

## 🧪 Flujo del pipeline

1. **Extracción de datos desde API externa**
2. **Almacenamiento en MySQL (RAW)**
3. **Preprocesamiento, limpieza y división (CLEAN)**
4. **Entrenamiento con `LinearRegression`**
5. **Registro de métricas y modelos en MLflow**
6. **Selección y guardado del mejor modelo**
7. **Monitoreo de la API con Prometheus + Grafana**

---

## ⚙️ Cómo ejecutar el proyecto

### 1. Crear red Docker externa

```bash
docker network create mlops_net
```

### 2. Levantar todos los servicios

```bash
docker compose -f docker-compose.yml \
               -f docker-compose-mlflow.yml \
               -f docker-compose-airflow.yml up -d --build
```

### 3. Acceder a las interfaces

- Airflow: [http://localhost:8080](http://localhost:8080)
- MLflow: [http://localhost:8084](http://localhost:8084)
- MinIO: [http://localhost:8083](http://localhost:8083)
- Streamlit: [http://localhost:8501](http://localhost:8501)
- Grafana: [http://localhost:3000](http://localhost:3000)

> Usuario y contraseña por defecto de Grafana: `admin / admin`

---

## 📁 DAG principal (`pipeline.py`)

Se ejecuta secuencialmente en Airflow:

- `fase_1_extraccion`: consumo condicional de nuevos batches
- `fase_2_limpieza_y_division`: preprocesamiento y partición en train/val/test
- `fase_3_entrenamiento_modelo`: entrenamiento y registro en MLflow + MinIO

---

## 📌 Notas adicionales

- Los modelos son almacenados localmente y en MLflow (vía MinIO).
- Las métricas se registran también en base de datos para análisis posterior.
- El sistema puede ser extendido con alertas y despliegue de modelos vía API.
