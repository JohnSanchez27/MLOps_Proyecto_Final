# ğŸ“Œ Proyecto Final MLOps - Entrenamiento y Monitoreo de Modelos

Este proyecto implementa un pipeline completo de MLOps para un sistema de predicciÃ³n inmobiliaria. Incluye desde el entrenamiento, versionamiento y despliegue de modelos ML, hasta la interfaz para consumo de predicciones y monitoreo de mÃ©tricas.

---

## ğŸ“¦ Arquitectura del Proyecto

El proyecto estÃ¡ compuesto por varios servicios orquestados con Docker Compose que interactÃºan en una red llamada mlops_net:

    - MySQL: Base de datos para almacenar el backend de MLflow.
    - MinIO: Servicio de almacenamiento compatible con S3 para guardar artefactos (modelos, datasets, etc.).
    - MLflow: Servidor de tracking y model registry para gestiÃ³n de modelos.
    - FastAPI: API backend que expone endpoints para realizar predicciones usando modelos versionados en MLflow.
    - Streamlit: Interfaz web frontend para interacciÃ³n y visualizaciÃ³n de resultados.
    - Prometheus & Grafana: Herramientas para monitoreo y visualizaciÃ³n de mÃ©tricas del sistema.

```
PROYECTO_FINAL/
â”œâ”€â”€ app_back/
â”‚   â”œâ”€â”€ dockerfile_api
â”‚   â”œâ”€â”€ main.py
â”‚   â””â”€â”€ requirements_api.txt
â”œâ”€â”€ app_front/                              # Frontend con Streamlit
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ dockerfile_stream
â”‚   â””â”€â”€ requirements_app.txt
â”œâ”€â”€ connections/                            # Conexiones a bases de datos
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ connections.py
â”œâ”€â”€ dags/                                   # DAGs de Airflow (pipeline unificado)
â”‚   â””â”€â”€ pipeline.py
â”œâ”€â”€ grafana/                                # Dashboards y configuraciÃ³n    
â”‚   â””â”€â”€ provisioning/
â”‚       â”œâ”€â”€ dashboards/
â”‚       â”‚   â””â”€â”€ fastapi_dashboard.json
â”‚       â”œâ”€â”€ datasources/
â”‚       â””â”€â”€ dashboards.yml
â”œâ”€â”€ imagenes/
â”œâ”€â”€ logs/                                   # Logs de Airflow
â”œâ”€â”€ minio/                                  # Almacenamiento S3 
â”œâ”€â”€ mlflow/                                 # ConfiguraciÃ³n de MLflow
â”‚   â”œâ”€â”€ dockerfile_mlflow
â”‚   â”œâ”€â”€ init.sql
â”‚   â””â”€â”€ requirements_mlflow.txt
â”œâ”€â”€ models/                                # Modelos y artefactos generados
â”‚   â”œâ”€â”€ columnas_entrenamiento.json
â”‚   â””â”€â”€ modelo_mejor.pkl
â”œâ”€â”€ prometheus/                           # ConfiguraciÃ³n de Prometheus
â”‚   â””â”€â”€ prometheus.yml
â”œâ”€â”€ docker-composeairflow.yml             # Servicios Airflow
â”œâ”€â”€ docker-composemlflow.yml              # Servicio MLflow, MiniO y SQL
â”œâ”€â”€ docker-compose.yml                    # Base:  Streamlit, FastApi, Prometheus y grafana
â”œâ”€â”€ dockerfile
â””â”€â”€ requirements.txt
```
---

## ğŸš€ Servicios principales

| Servicio     | Puerto | DescripciÃ³n |
|--------------|--------|-------------|
| **Airflow**  | `8080` | OrquestaciÃ³n del pipeline de datos |
| **MLflow**   | `8084` | Registro de experimentos y modelos |
| **MinIO**    | `8083` | Almacenamiento tipo S3 para artefactos |
| **Streamlit**| `8501` | VisualizaciÃ³n de resultados |
| **FastAPI**  | `8000` | Backend API |
| **Grafana**  | `3000` | VisualizaciÃ³n de mÃ©tricas |
| **Prometheus** | `9090` | RecolecciÃ³n de mÃ©tricas |
| **MySQL**    | `3306` | Base de datos principal |

---

## ğŸ§ª Flujo del pipeline

1. **ExtracciÃ³n de datos desde API externa**
2. **Almacenamiento en MySQL (RAW)**
3. **Preprocesamiento, limpieza y divisiÃ³n (CLEAN)**
4. **Entrenamiento con `LinearRegression`**
5. **Registro de mÃ©tricas y modelos en MLflow**
6. **SelecciÃ³n y guardado del mejor modelo**
7. **Monitoreo de la API con Prometheus + Grafana**

---

## âš™ï¸ CÃ³mo ejecutar el proyecto

### 1. Crear red Docker externa

```bash
docker network create mlops_net
```

### 2. Levantar todos los servicios

```bash
docker compose -f docker-compose.yml \
               -f docker-composemlflow.yml \
               -f docker-composeairflow.yml up -d --build
```

### 3. Acceder a las interfaces

- Airflow: [http://localhost:8080](http://localhost:8080)

![alt text](imagenes/Airflow_Dags.png)

- MLflow: [http://localhost:8084](http://localhost:8084)
![alt text](imagenes/mlflow_models.png)

- MinIO: [http://localhost:8083](http://localhost:8083)

![alt text](imagenes/MiniO_Bucket.png)

- FastApi: [http://localhost:8000](http://localhost:8000/docs)

![alt text](imagenes/FastApi.png)

- Streamlit: [http://localhost:8501](http://localhost:8501)
![alt text](imagenes/Streamlit_Prediccin.png)

- Grafana: [http://localhost:3000](http://localhost:3000)
![alt text](imagenes/Observabilidad_Graphana.png)

- Prometheus: [http://localhost:9090](http://localhost:9090)
![alt text](imagenes/Prometheus.png)

> Usuario y contraseÃ±a por defecto de Grafana: `admin / admin`
> Usuario y contraseÃ±a por defecto de MiniO `admin / supersecret`
> Usuario y contraseÃ±a por defecto de Airflow `airflow / airflow`

---

## ğŸ“ DAG principal (`pipeline.py`)

Se ejecuta secuencialmente en Airflow:

- `fase_1_extraccion`: consumo condicional de nuevos batches
- `fase_2_limpieza_y_division`: preprocesamiento y particiÃ³n en train/val/test
- `fase_3_entrenamiento_modelo`: entrenamiento y registro en MLflow + MinIO

![Airflow](imagenes/Pipeline_Airflow.png)
---

## ğŸ“Œ Notas adicionales

- Los modelos son almacenados localmente y en MLflow (vÃ­a MinIO).
- Las mÃ©tricas se registran tambiÃ©n en base de datos para anÃ¡lisis posterior y se guarda el modelo en con la etiqueta de produccion
- El sistema puede ser extendido con alertas y despliegue de modelos vÃ­a API.

## ğŸ“  Despliegue total con Kubertnets

